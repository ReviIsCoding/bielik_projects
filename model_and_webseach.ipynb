{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import pandas as pandas\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zmienne do usunięcia przy przejściu na skrypt\n",
    "dataset_URL = \"To Do - wstawić link do datasetu\"\n",
    "model_id = \"To Do - wstawić id modelu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the main function\n",
    "def main():\n",
    "    '''\n",
    "    The script's main function.\n",
    "    '''\n",
    "    print(\"Getting started...\")\n",
    "    # loading the dataset\n",
    "    df = pd.read_csv(dataset_URL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary definitions\n",
    "def load_dataset(dataset_URL):\n",
    "    \"\"\"\n",
    "    Loads data from CSV and removes redundant columns\n",
    "\n",
    "    Args:\n",
    "        dataset_url (str): URL of the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Loading dataset\n",
    "    df = pd.read_csv(dataset_URL)\n",
    "\n",
    "    # Removing excessive columns (e.g. 'Unnamed')\n",
    "    df.drop(columns=df.columns[df.columns.str.contains('^Unnamed')], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def load_model_and_tokenizer(model_name):\n",
    "    \"\"\"\n",
    "    Loading model Bielik-11-B-v2.3-Instruct from Huggingface \n",
    "    and tokenizer for the model.\n",
    "    \"\"\"\n",
    "    # Loading model\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "    # Loading tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "def create_pipeline(model, tokenizer):\n",
    "    \"\"\"\n",
    "    Creates a pipeline for the model and tokenizer.\n",
    "\n",
    "    Args:\n",
    "        model (transformers.PreTrainedModel): Model.\n",
    "        tokenizer (transformers.PreTrainedTokenizer): Tokenizer.\n",
    "\n",
    "    Returns:\n",
    "        transformers.Pipeline: Pipeline.\n",
    "    \"\"\"\n",
    "    # Creating pipeline\n",
    "    pipeline = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def querry_llm(df, pipeline):\n",
    "    \"\"\"\n",
    "    Generates answers for the questions in the 'question' column and saves them in a new column.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with 'question' column.\n",
    "        pipe: Pipeline of the language model.\n",
    "        pipeline (transformers.Pipeline): Pipeline.\n",
    "\n",
    "    Returns:\n",
    "       Returns:\n",
    "        pd.DataFrame: Updated DataFrame with a new column \"llm_answer\".\n",
    "    \"\"\"\n",
    "    # Querying the model\n",
    "    if \"question\" not in df.columns:\n",
    "        raise ValueError(\"DataFrame must contain a 'question' column.\")\n",
    "    # Iterate through questions and generate answers\n",
    "    answers = []\n",
    "    for inx, question in enumerate(df[\"question\"], start=1):\n",
    "        print(f\"Processing question {inx}/{len(df)}...\")\n",
    "        response = pipeline(question)\n",
    "        generated_text = response[0][\"generated_text\"]\n",
    "        print(f\"Response: {generated_text}\")\n",
    "\n",
    "        answers.append(generated_text)\n",
    "    # Adding answers to the DataFrame\n",
    "    df[\"llm_answer\"] = answers\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_web(df, num_results):\n",
    "    \"\"\"\n",
    "    Searches the web for the question and returns the top results.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with 'question' column.\n",
    "        num_results (int): Number of top results to return.\"\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with a new column \"web_results\" (list of URLs).\n",
    "        \"\"\"\n",
    "    # Searching the web\n",
    "    if \"question\" not in df.columns:\n",
    "        raise ValueError(\"DataFrame must contain a 'question' column.\")\n",
    "    # Iterate through questions and search the web\n",
    "    web_results = []\n",
    "    for idx, question in enumerate(df[\"question\"], start=1):\n",
    "        print(f\"Searching the web for question {idx}/{len(df)}...\")\n",
    "        search_url = f\"https://duckduckgo.com/html/?q={question}\"\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        response = requests.get(search_url, headers=headers)\n",
    "        \n",
    "        # get the URL of the first num_results\n",
    "        links = [line for line in response.text.split('\"') if line.startswith(\"http\")][:num_results]\n",
    "        print(f\"Found {len(links)} results.\")\n",
    "        web_results.append(links)\n",
    "        sleep(2)\n",
    "    # Adding web results to the DataFrame\n",
    "    df[\"web_results\"] = web_results\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
